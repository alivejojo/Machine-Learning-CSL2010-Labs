# -*- coding: utf-8 -*-
"""B20BB047_Task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JoQJcnnK5izotVoec27vPP6JdeLgeFG1
"""

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt

df = pd.read_csv('mnist_train.csv')
df.head()

df.shape

y_train = df.label
x_train = df.drop(columns=['label'])

x_train1 = x_train.to_numpy()
y_train1 = y_train.to_numpy()

# visualize one image:
plt.imshow(x_train1[0].reshape(28,28))

# sampling 5000 images
df_sampled = df.sample(n=5000, axis = 0, random_state = 3)
print(df_sampled.shape)
df_sampled.head()

x_train_sample = df_sampled.drop(columns=['label']).to_numpy()
y_train_sampled = df_sampled.label.to_numpy()

x_train1[:][1].mean()

def covariance_mx(X):

    N=len(X[0])
    n=len(X)
    cov_X = np.zeros((N,N))
    for i in range(N):
        for j in range(N):
            s=0
            for k in range(n):
                s = s + ( X[k][i]-X[:,i].mean() )*( X[k][j]-X[:,j].mean() )
            s = s/(n-1)
            cov_X[i][j] = s

    return cov_X

# just to check
n2=np.array([[1,1,1],[1,2,3]])

print(covariance_mx(n2))

# print(covariance_mx(X_train_sample))
# this method takes too long O(N^2*n)

def covariance_mx_fst(X):
   X2=np.ones((len(X),len(X))) 
   X_ = X - (1/len(X))*np.matmul(X2,X)

   return np.matmul(X_.T,X_)*(1/len(X))

print(covariance_mx_fst(n2))

# we find covariance matrix of standardized X_train_sample. 
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
Z = scaler.fit_transform(x_train_sample)

cov_X_train = covariance_mx_fst(Z)

print(cov_X_train)

cov_X_train.shape

print(np.count_nonzero(cov_X_train==0))
# 6,14,656 total values of which 1,75,087 are non zero

# eigen decomposition of a matrix cov_X_train
from numpy import linalg as LA

eigen_Vals, eigen_normalized_vectors = LA.eig(cov_X_train) # w-> eigen values, and v -> normalized eigen vectors

# v gives eigen vectors corresponding to the eigen vlaues of w. 
# if we sort by eigen value, we also hav to rearrange the vectors
print(np.count_nonzero(eigen_Vals==0))
eigen_Vals.shape

eigen_Vals

eigen_normalized_vectors

eigen_normalized_vectors.shape

# loop over columns v[:,i] is the eigenvector corresponding to the eigenvalue w[i]
eigen_Vals = np.real(eigen_Vals)
eigen_normalized_vectors = np.real(eigen_normalized_vectors)

for i in range(784):
    for j in range(i,784):
        if eigen_Vals[j]>eigen_Vals[i]:
            temp = eigen_Vals[i]
            eigen_Vals[i] = eigen_Vals[j]
            eigen_Vals[j] = temp 

            temp_v = eigen_normalized_vectors[:,i]
            eigen_normalized_vectors[:,i] = eigen_normalized_vectors[:,j]
            eigen_normalized_vectors[:,j] = temp_v

print(eigen_Vals)

# yes it is in descending order now 

# print first 5 eigen values
print(eigen_Vals[0:5])

# taking two random rows/ images from the scaled df_sample = Z 
random_indices = np.random.choice(5000, size=2, replace=False)
two_images = Z[random_indices, :]
print(two_images)

plt.imshow(two_images[0].reshape(28,28))
# for num_of_pcs in [10,50,100,300,700]:

#     eigen_Vals_tbu = eigen_Vals[0:num_of_pcs]
#     eigen_normalized_vectors_tbu = eigen_normalized_vectors[0:num_of_pcs] # tbu = to be used

plt.imshow(two_images[1].reshape(28,28))

def reconstruct(num_of_pcs, X):
    X_new = np.zeros((num_of_pcs,))

    eigen_normalized_vectors_tbu = eigen_normalized_vectors[:,:num_of_pcs]
    for i in range(num_of_pcs):
        X_new[i] = np.dot(X,eigen_normalized_vectors_tbu[:,i])

    return X_new

reduced_img1_10 = reconstruct(10,two_images[0])
reduced_img2_10 = reconstruct(10,two_images[1])
reduced_img1_50 = reconstruct(50,two_images[0])
reduced_img2_50 = reconstruct(50,two_images[1])
reduced_img1_100 = reconstruct(100,two_images[0])
reduced_img2_100 = reconstruct(100,two_images[1])
reduced_img1_300 = reconstruct(300,two_images[0])
reduced_img2_300 = reconstruct(300,two_images[1])
reduced_img1_700 = reconstruct(700,two_images[0])
reduced_img2_700 = reconstruct(700,two_images[1])

two_images.shape

# okay so we need to inverse PCA
reconstructed_img1_10 = np.dot ( eigen_normalized_vectors[:,:10] ,reduced_img1_10)
reconstructed_img2_10 = np.dot ( eigen_normalized_vectors[:,:10] ,reduced_img2_10)

reconstructed_img1_50 = np.dot ( eigen_normalized_vectors[:,:50] ,reduced_img1_50)
reconstructed_img2_50 = np.dot ( eigen_normalized_vectors[:,:50] ,reduced_img2_50)

reconstructed_img1_100 = np.dot ( eigen_normalized_vectors[:,:100] ,reduced_img1_100)
reconstructed_img2_100 = np.dot ( eigen_normalized_vectors[:,:100] ,reduced_img2_100)

reconstructed_img1_300 = np.dot ( eigen_normalized_vectors[:,:300] ,reduced_img1_300)
reconstructed_img2_300 = np.dot ( eigen_normalized_vectors[:,:300] ,reduced_img2_300)

reconstructed_img1_700 = np.dot ( eigen_normalized_vectors[:,:700] ,reduced_img1_700)
reconstructed_img2_700 = np.dot ( eigen_normalized_vectors[:,:700] ,reduced_img2_700)

plt.imshow(reconstructed_img1_10.reshape(28,28))

residual_img1_10 = reconstructed_img1_10 - two_images[0]
plt.imshow(residual_img1_10.reshape(28,28))

residual_img2_10 = reconstructed_img2_10 - two_images[1]
residual_img1_50 = reconstructed_img1_50 - two_images[0]
residual_img2_50 = reconstructed_img2_50 - two_images[1]
residual_img1_100 = reconstructed_img1_100 - two_images[0]
residual_img2_100 = reconstructed_img2_100 - two_images[1]
residual_img1_300 = reconstructed_img1_300 - two_images[0]
residual_img2_300 = reconstructed_img2_300 - two_images[1]
residual_img1_700 = reconstructed_img1_700 - two_images[0]
residual_img2_700 = reconstructed_img2_700 - two_images[1]
plt.title( "2nd image with 10 PCS")
plt.imshow(residual_img2_10.reshape(28,28))

plt.title( "1st resiudal image with 50 PCS")
plt.imshow(residual_img1_50.reshape(28,28))

plt.title( "2nd residual image with 50 PCS")
plt.imshow(residual_img2_50.reshape(28,28))

plt.title( "1st residual image with 100 PCS")
plt.imshow(residual_img1_100.reshape(28,28))

plt.title( "2nd residual image with 100 PCS")
plt.imshow(residual_img2_100.reshape(28,28))

plt.title( "1st residual image with 300 PCS")
plt.imshow(residual_img1_300.reshape(28,28))

plt.title( "2nd residual image with 300 PCS")
plt.imshow(residual_img2_300.reshape(28,28))

plt.title( "1st residual image with 700 PCS")
plt.imshow(residual_img1_700.reshape(28,28))

plt.title( "2nd residual image with 700 PCS")
plt.imshow(residual_img2_700.reshape(28,28))

reconstructed_images = [residual_img1_10, 
reconstructed_img2_10, 
reconstructed_img1_50, 
reconstructed_img2_50, 
reconstructed_img1_100,
reconstructed_img2_100,
reconstructed_img1_300, 
reconstructed_img2_300, 
reconstructed_img1_700, 
reconstructed_img2_700]

residual_images_1 = [residual_img1_10, 
residual_img1_50,
residual_img1_100,
residual_img1_300,
residual_img1_700]

# 2.6 pixel wise root-mean-square for each sample and plot them for different number of PCS
error = []
for i in range(5):
    error.append(np.sqrt(np.sum( residual_images_1[i]*residual_images_1[i])))
plt.title("pixel wise RMS error added for 1st image")
plt.xlabel("PCS's retained")
plt.xlabel("RMS error")
plt.scatter([10,50,100,300,700],error)

print(error)
