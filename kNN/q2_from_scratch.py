# -*- coding: utf-8 -*-
"""Lab4_B20BB047.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PEjPxBsN3OwJ2eRXFpCGvN1fvrZpynzn
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("diabetes (1).csv")
df.head()

# just for plotting

x_Axis = np.arange(768)
y_axis = df[['Outcome']].to_numpy()
plt.scatter(df[['Glucose']].to_numpy(), y_axis)
plt.show()

def check_zeros(clm):

  s=0
  for i in range(len(clm)):
    if clm[i] == [0]: 
      s = s + 1
  return s

print("number of zeros in : ")
for i in list(df.columns):
  
  print(i, " -> ", check_zeros(   df[[i]].to_numpy()  ))

# zeros in Pregnancies and Outcomes makes sense. 
# 0's in Glucose, BloodPressure, SkinThickness, BMI don't make sense
# we impute them by mean values of the respective features

def impute_by_mean (clm):

  for i in range(df[clm].values.shape[0]):
    if df[clm].values[i] == 0:
      df[clm].values[i] = df[clm].mean()

impute_by_mean('Glucose')
impute_by_mean('BloodPressure')
impute_by_mean('SkinThickness')
impute_by_mean('BMI')

print("number of zeros in : ")
for i in list(df.columns):
  
  print(i, " -> ", check_zeros(   df[[i]].to_numpy()  ))

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
features_scaled = scaler.fit_transform (df.drop('Outcome',axis=1))

df_scaled = pd.DataFrame(features_scaled, columns = df.columns[:-1])
df_scaled.head()

# Split the dataset into 70:30
from sklearn.model_selection import train_test_split

X_train, X_temp, y_train, y_temp = train_test_split(df_scaled, df[['Outcome']], test_size=0.3)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size = 0.5)

X_train = X_train.to_numpy()
X_val = X_val.to_numpy()
X_test = X_test.to_numpy()
y_train = y_train.to_numpy()
y_test = y_test.to_numpy()
y_val = y_val.to_numpy()

import math as m
def euclidean_dist(v1,v2):
  # distance between two feature vectors i.e rows 
  d = 0
  for i in range(len(v1)):
    d = d + (v1[i]-v2[i])**2

  return m.sqrt(d)

def knn(X,u,k):
  # a is column of distance between all rows of X_train and u
  # c keeps indexes of k shortest distances in a
  # in c .. index of k shortest distance... same index is row_number in X_train 
  # b keeps +1 for class 0 or -1 for class 1 wrt  

  u_pred_outcome = -1 
  a = [0 for i in range(len(X))]
  for i in range(len(X)):
    a[i] = euclidean_dist(X[i], u)

  c=[]
  a_copy = a
  for i in range(k):
    c.append(a.index(min(a)))
    a[a.index(min(a))] = max(a_copy)
  # c has index of k smallest euclidean distance.. index wrt to their row number in X_train 
  b=0
  for i in range(len(c)):
    if y_train[c[i]][-1] == 0:
      b=b-1
    elif y_train[c[i]][-1] == 1:
      b=b+1
  if b>0:
    u_pred_outcome = 1
  else:
    u_pred_outcome = 0
  return u_pred_outcome

X_val[0]

y_val_pred = [] 
error_list = []


for k in [5,11,15,17,21,27]:
  
  confusion_matrix = [[0,0],[0,0]]
  accuracy = 0

  error = 0
  y_val_pred = []
  for i in range(len(X_val)):
    y_val_pred.append(knn(X_train, X_val[i], k))  

  for j in range(len(y_val_pred)):
    if y_val_pred[j]!=y_val[j]:
      error = error + 1 
      if y_val_pred[j]==1:
        confusion_matrix[0][1] = confusion_matrix[0][1] + 1
      else:
        confusion_matrix[1][0] = confusion_matrix[1][0] + 1
    else:
      
      if y_val_pred[j] == 1:
        confusion_matrix[0][0] = confusion_matrix[0][0] + 1
      else:
        confusion_matrix[1][1] = confusion_matrix[1][1] + 1

    accuracy = ((confusion_matrix[0][0] + confusion_matrix[1][1])/len(y_val))*100
  error = error/789
  error_list.append(error)
  print("k = ",k)
  print("confusion matrix : ", confusion_matrix)
  print("accuracy: ", accuracy)
  print()



plt.scatter([5,11,15,17,21,27],error_list)
plt.show()

# now using k=17 for library implementation of KNN


from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=17)
knn.fit(X_train,y_train)
pred = knn.predict(X_val)

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_val,pred))
print("accuracy : " ,( ( list(confusion_matrix(y_val,pred))[0][0] + list(confusion_matrix(y_val,pred))[1][1]) /len(y_val))*100  )
print(classification_report(y_val,pred))

"""Accuracy for k=17 form ***scratch*** on the validation set = 76.52173913043478

Accuracy for k=17 form ***library*** on the validation set = 76.52173913043478




"""
